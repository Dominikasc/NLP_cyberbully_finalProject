{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import nltk.corpus # sample text for performing tokenization\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from gensim.utils import simple_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>annotation</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>cat_enc</th>\n",
       "      <th>ed_label_0</th>\n",
       "      <th>ed_label_1</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>['wrong', 'isi', 'follows', 'example', 'mohamm...</td>\n",
       "      <td>['wrong', 'isi', 'follow', 'exampl', 'moham', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>@SirajZarook @OdiniaInvictus @BilalIGhumman @I...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>good muslim good despite bad religion</td>\n",
       "      <td>['good', 'muslim', 'good', 'despite', 'bad', '...</td>\n",
       "      <td>['good', 'muslim', 'good', 'despit', 'bad', 'r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>@scamp_faridxx @AbuAlbaraaSham Yeah, it's call...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>yeah called caring human life idiot something ...</td>\n",
       "      <td>['yeah', 'called', 'caring', 'human', 'life', ...</td>\n",
       "      <td>['yeah', 'call', 'care', 'human', 'life', 'idi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>@Asadumarfans You are a Muslim. You are brain ...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>muslim brain dead repeat others said million time</td>\n",
       "      <td>['muslim', 'brain', 'dead', 'repeat', 'others'...</td>\n",
       "      <td>['muslim', 'brain', 'dead', 'repeat', 'other',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>@harmlesstree2 @MaxBlumenthal If you want to u...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>want understand lie muslim living peace jew re...</td>\n",
       "      <td>['want', 'understand', 'lie', 'muslim', 'livin...</td>\n",
       "      <td>['want', 'understand', 'lie', 'muslim', 'live'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0             0           0   \n",
       "1             1             1           1   \n",
       "2             2             2           2   \n",
       "3             3             3           3   \n",
       "4             4             4           4   \n",
       "\n",
       "                                                text annotation  oh_label  \\\n",
       "0  @g0ssipsquirrelx Wrong, ISIS follows the examp...     racism       1.0   \n",
       "1  @SirajZarook @OdiniaInvictus @BilalIGhumman @I...     racism       1.0   \n",
       "2  @scamp_faridxx @AbuAlbaraaSham Yeah, it's call...     racism       1.0   \n",
       "3  @Asadumarfans You are a Muslim. You are brain ...     racism       1.0   \n",
       "4  @harmlesstree2 @MaxBlumenthal If you want to u...     racism       1.0   \n",
       "\n",
       "   cat_enc ed_label_0 ed_label_1 hashtags  \\\n",
       "0        1                             []   \n",
       "1        1                             []   \n",
       "2        1                             []   \n",
       "3        1                             []   \n",
       "4        1                             []   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0   wrong isi follows example mohammed quran exactly   \n",
       "1              good muslim good despite bad religion   \n",
       "2  yeah called caring human life idiot something ...   \n",
       "3  muslim brain dead repeat others said million time   \n",
       "4  want understand lie muslim living peace jew re...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  ['wrong', 'isi', 'follows', 'example', 'mohamm...   \n",
       "1  ['good', 'muslim', 'good', 'despite', 'bad', '...   \n",
       "2  ['yeah', 'called', 'caring', 'human', 'life', ...   \n",
       "3  ['muslim', 'brain', 'dead', 'repeat', 'others'...   \n",
       "4  ['want', 'understand', 'lie', 'muslim', 'livin...   \n",
       "\n",
       "                                      stemmed_tokens  \n",
       "0  ['wrong', 'isi', 'follow', 'exampl', 'moham', ...  \n",
       "1  ['good', 'muslim', 'good', 'despit', 'bad', 'r...  \n",
       "2  ['yeah', 'call', 'care', 'human', 'life', 'idi...  \n",
       "3  ['muslim', 'brain', 'dead', 'repeat', 'other',...  \n",
       "4  ['want', 'understand', 'lie', 'muslim', 'live'...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing twitter dataset\n",
    "\n",
    "twitter_df = pd.read_csv('data/twitter_all_data.csv',index_col=False)\n",
    "twitter_df=twitter_df.fillna(\"\")\n",
    "\n",
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>annotation</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>cat_enc</th>\n",
       "      <th>ed_label_0</th>\n",
       "      <th>ed_label_1</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0.2, Unnamed: 0.1, Unnamed: 0, text, annotation, oh_label, cat_enc, ed_label_0, ed_label_1, hashtags, tokenized, tokenized_text, stemmed_tokens]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df[twitter_df['oh_label']=='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['wrong',\n",
       "  'isi',\n",
       "  'follows',\n",
       "  'example',\n",
       "  'mohammed',\n",
       "  'quran',\n",
       "  'exactly',\n",
       "  'good',\n",
       "  'muslim',\n",
       "  'good',\n",
       "  'despite',\n",
       "  'bad',\n",
       "  'religion',\n",
       "  'yeah',\n",
       "  'called',\n",
       "  'caring',\n",
       "  'human',\n",
       "  'life',\n",
       "  'idiot',\n",
       "  'something',\n",
       "  'genocidal',\n",
       "  'daesh',\n",
       "  'would',\n",
       "  'nt',\n",
       "  'understand',\n",
       "  'muslim',\n",
       "  'brain',\n",
       "  'dead',\n",
       "  'repeat',\n",
       "  'others',\n",
       "  'said',\n",
       "  'million',\n",
       "  'time',\n",
       "  'want',\n",
       "  'understand',\n",
       "  'lie',\n",
       "  'muslim',\n",
       "  'living',\n",
       "  'peace',\n",
       "  'jew',\n",
       "  'read',\n",
       "  'ibn',\n",
       "  'warraq',\n",
       "  'total',\n",
       "  'liar',\n",
       "  'like',\n",
       "  'pedophile',\n",
       "  'prophet',\n",
       "  'un',\n",
       "  'soldier',\n",
       "  'burn',\n",
       "  'people',\n",
       "  'alive',\n",
       "  'daesh',\n",
       "  'shia',\n",
       "  'militia',\n",
       "  'driven',\n",
       "  'religion',\n",
       "  'hatred',\n",
       "  'bigotry',\n",
       "  'freedom',\n",
       "  'tikrit',\n",
       "  'regardless',\n",
       "  'muslim',\n",
       "  'world',\n",
       "  'ever',\n",
       "  'produced',\n",
       "  'anything',\n",
       "  'tyrant',\n",
       "  'dictator',\n",
       "  'fascist',\n",
       "  'fanatic',\n",
       "  'would',\n",
       "  'support',\n",
       "  'islam',\n",
       "  'answer',\n",
       "  'anything',\n",
       "  'pretend',\n",
       "  'answer',\n",
       "  'illogical',\n",
       "  'delusional',\n",
       "  'superstition',\n",
       "  'attacking',\n",
       "  'everyone',\n",
       "  'follows',\n",
       "  'religious',\n",
       "  'cult',\n",
       "  'hated',\n",
       "  'murder',\n",
       "  'like',\n",
       "  'islam',\n",
       "  'liar',\n",
       "  'beheaded',\n",
       "  'jewish',\n",
       "  'men',\n",
       "  'one',\n",
       "  'day',\n",
       "  'sold',\n",
       "  'woman',\n",
       "  'child',\n",
       "  'slavery',\n",
       "  'islam',\n",
       "  'race',\n",
       "  'microbrain',\n",
       "  'death',\n",
       "  'cult',\n",
       "  'stupidist',\n",
       "  'argument',\n",
       "  'one',\n",
       "  'rationalizing',\n",
       "  'barbarity',\n",
       "  'islam',\n",
       "  'rofl',\n",
       "  'jew',\n",
       "  'used',\n",
       "  'live',\n",
       "  'arabian',\n",
       "  'peninsula',\n",
       "  'committing',\n",
       "  'genocide',\n",
       "  'rt',\n",
       "  'good',\n",
       "  'morning',\n",
       "  'pissed',\n",
       "  'american',\n",
       "  'patriot',\n",
       "  'cop',\n",
       "  'danger',\n",
       "  'religion',\n",
       "  'islam',\n",
       "  'built',\n",
       "  'apartheid',\n",
       "  'ethnic',\n",
       "  'cleansing',\n",
       "  'rt',\n",
       "  'isi',\n",
       "  'trying',\n",
       "  'stop',\n",
       "  'people',\n",
       "  'fleeing',\n",
       "  'talabyad',\n",
       "  'gre',\n",
       "  'spi',\n",
       "  'lie',\n",
       "  'tht',\n",
       "  'thy',\n",
       "  'captured',\n",
       "  'rocket',\n",
       "  'voice',\n",
       "  'hit',\n",
       "  'near',\n",
       "  'choose',\n",
       "  'define',\n",
       "  'quran',\n",
       "  'follower',\n",
       "  'extremist',\n",
       "  'care',\n",
       "  'revised',\n",
       "  'million',\n",
       "  'time',\n",
       "  'barbarity',\n",
       "  'islam',\n",
       "  'mohammed',\n",
       "  'people',\n",
       "  'murdered',\n",
       "  'disagreed',\n",
       "  'raped',\n",
       "  'woman',\n",
       "  'married',\n",
       "  'year',\n",
       "  'old',\n",
       "  'beheaded',\n",
       "  'jew',\n",
       "  'salon',\n",
       "  'try',\n",
       "  'shut',\n",
       "  'free',\n",
       "  'speech',\n",
       "  'shut',\n",
       "  'people',\n",
       "  'playing',\n",
       "  'race',\n",
       "  'card',\n",
       "  'ideaology',\n",
       "  'let',\n",
       "  'people',\n",
       "  'read',\n",
       "  'quran',\n",
       "  'see',\n",
       "  'come',\n",
       "  'hate',\n",
       "  'true',\n",
       "  'islam',\n",
       "  'corrupt',\n",
       "  'beginning',\n",
       "  'feed',\n",
       "  'little',\n",
       "  'piece',\n",
       "  'taqiyya',\n",
       "  'rt',\n",
       "  'article',\n",
       "  'islamist',\n",
       "  'welfare',\n",
       "  'paid',\n",
       "  'plot',\n",
       "  'west',\n",
       "  'demise',\n",
       "  'idiot',\n",
       "  'history',\n",
       "  'would',\n",
       "  'say',\n",
       "  'thatyou',\n",
       "  'never',\n",
       "  'studied',\n",
       "  'barbarity',\n",
       "  'muslim',\n",
       "  'entire',\n",
       "  'time',\n",
       "  'mean',\n",
       "  'send',\n",
       "  'muslim',\n",
       "  'back',\n",
       "  'middle',\n",
       "  'east',\n",
       "  'turn',\n",
       "  'europe',\n",
       "  'sewer',\n",
       "  'mohammed',\n",
       "  'first',\n",
       "  'wife',\n",
       "  'katjia',\n",
       "  'wealthy',\n",
       "  'woman',\n",
       "  'islam',\n",
       "  'lying',\n",
       "  'muslim',\n",
       "  'extermination',\n",
       "  'jew',\n",
       "  'rt',\n",
       "  'woman',\n",
       "  'subjected',\n",
       "  'brutal',\n",
       "  'abnormal',\n",
       "  'sex',\n",
       "  'act',\n",
       "  'marrying',\n",
       "  'isi',\n",
       "  'militant',\n",
       "  'big',\n",
       "  'lie',\n",
       "  'advocate',\n",
       "  'tolerance',\n",
       "  'coexistence',\n",
       "  'advocate',\n",
       "  'hatred',\n",
       "  'murder',\n",
       "  'try',\n",
       "  'get',\n",
       "  'education',\n",
       "  'repeat',\n",
       "  'lie',\n",
       "  'stupidity',\n",
       "  'get',\n",
       "  'imam',\n",
       "  'rt',\n",
       "  'people',\n",
       "  'work',\n",
       "  'hard',\n",
       "  'make',\n",
       "  'world',\n",
       "  'better',\n",
       "  'place',\n",
       "  'others',\n",
       "  'work',\n",
       "  'hard',\n",
       "  'book',\n",
       "  'drink',\n",
       "  'sex',\n",
       "  'party',\n",
       "  'next',\n",
       "  'door',\n",
       "  'pakistan',\n",
       "  'muslim',\n",
       "  'still',\n",
       "  'murder',\n",
       "  'christian',\n",
       "  'hindu',\n",
       "  'regularly',\n",
       "  'read',\n",
       "  'entire',\n",
       "  'quran',\n",
       "  'much',\n",
       "  'hadith',\n",
       "  'know',\n",
       "  'islam',\n",
       "  'muslim',\n",
       "  'curse',\n",
       "  'mankind',\n",
       "  'comparing',\n",
       "  'thousand',\n",
       "  'jewish',\n",
       "  'extremist',\n",
       "  'million',\n",
       "  'muslim',\n",
       "  'extremist',\n",
       "  'religion',\n",
       "  'ready',\n",
       "  'murder',\n",
       "  'apostate',\n",
       "  'moderate',\n",
       "  'muslim',\n",
       "  'woman',\n",
       "  'convert',\n",
       "  'islam',\n",
       "  'marry',\n",
       "  'muslim',\n",
       "  'men',\n",
       "  'men',\n",
       "  'convert',\n",
       "  'prison',\n",
       "  'actual',\n",
       "  'spirituality',\n",
       "  'buddhism',\n",
       "  'tao',\n",
       "  'zero',\n",
       "  'spirituality',\n",
       "  'islam',\n",
       "  'kiss',\n",
       "  'as',\n",
       "  'read',\n",
       "  'book',\n",
       "  'muslim',\n",
       "  'bigot',\n",
       "  'written',\n",
       "  'promote',\n",
       "  'fascist',\n",
       "  'murdering',\n",
       "  'genocide',\n",
       "  'humanity',\n",
       "  'another',\n",
       "  'race',\n",
       "  'baiting',\n",
       "  'idiot',\n",
       "  'brown',\n",
       "  'men',\n",
       "  'would',\n",
       "  'hate',\n",
       "  'hinduism',\n",
       "  'buddhism',\n",
       "  'tao',\n",
       "  'hate',\n",
       "  'islam',\n",
       "  'hell',\n",
       "  'palestinian',\n",
       "  'muslim',\n",
       "  'asshole',\n",
       "  'like',\n",
       "  'clearly',\n",
       "  'state',\n",
       "  'intention',\n",
       "  'religious',\n",
       "  'jihad',\n",
       "  'jew',\n",
       "  'tell',\n",
       "  'shit',\n",
       "  'sucking',\n",
       "  'muslim',\n",
       "  'bigot',\n",
       "  'like',\n",
       "  'recognize',\n",
       "  'history',\n",
       "  'crawled',\n",
       "  'cuntyou',\n",
       "  'think',\n",
       "  'photoshop',\n",
       "  'truth',\n",
       "  'machin',\n",
       "  'idiotic',\n",
       "  'never',\n",
       "  'million',\n",
       "  'native',\n",
       "  'american',\n",
       "  'died',\n",
       "  'disease',\n",
       "  'prophet',\n",
       "  'mohammed',\n",
       "  'started',\n",
       "  'hate',\n",
       "  'fest',\n",
       "  'jew',\n",
       "  'driving',\n",
       "  'three',\n",
       "  'jewish',\n",
       "  'tribe',\n",
       "  'medina',\n",
       "  'jew',\n",
       "  'completely',\n",
       "  'perished',\n",
       "  'much',\n",
       "  'arabian',\n",
       "  'kind',\n",
       "  'thing',\n",
       "  'prophet',\n",
       "  'mohammed',\n",
       "  'mohammed',\n",
       "  'never',\n",
       "  'looked',\n",
       "  'knowledge',\n",
       "  'believed',\n",
       "  'jinni',\n",
       "  'illiterate',\n",
       "  'believed',\n",
       "  'dog',\n",
       "  'ere',\n",
       "  'devil',\n",
       "  'meantime',\n",
       "  'palestinian',\n",
       "  'fucker',\n",
       "  'beheading',\n",
       "  'gay',\n",
       "  'honor',\n",
       "  'killing',\n",
       "  'that',\n",
       "  'muslim',\n",
       "  'react',\n",
       "  'traffic',\n",
       "  'light',\n",
       "  'turn',\n",
       "  'red',\n",
       "  'unfortunately',\n",
       "  'real',\n",
       "  'islam',\n",
       "  'defined',\n",
       "  'quran',\n",
       "  'hadith',\n",
       "  'backwards',\n",
       "  'inhuman',\n",
       "  'even',\n",
       "  'muslim',\n",
       "  'yes',\n",
       "  'muslim',\n",
       "  'bigot',\n",
       "  'murdering',\n",
       "  'christian',\n",
       "  'africa',\n",
       "  'decade',\n",
       "  'mohammed',\n",
       "  'imperialist',\n",
       "  'led',\n",
       "  'major',\n",
       "  'military',\n",
       "  'expedition',\n",
       "  'isi',\n",
       "  'imperialist',\n",
       "  'rt',\n",
       "  'simple',\n",
       "  'question',\n",
       "  'ask',\n",
       "  'complaining',\n",
       "  'muslim',\n",
       "  'etc',\n",
       "  'integrate',\n",
       "  'live',\n",
       "  'saying',\n",
       "  'islam',\n",
       "  'way',\n",
       "  'life',\n",
       "  'mean',\n",
       "  'tell',\n",
       "  'can',\n",
       "  'not',\n",
       "  'democracy',\n",
       "  'must',\n",
       "  'instead',\n",
       "  'follow',\n",
       "  'pedophile',\n",
       "  'skill',\n",
       "  'except',\n",
       "  'jihad',\n",
       "  'rt',\n",
       "  'muhammad',\n",
       "  'inventor',\n",
       "  'thighing',\n",
       "  'started',\n",
       "  'molesting',\n",
       "  'aisha',\n",
       "  'year',\n",
       "  'old',\n",
       "  'cc',\n",
       "  'absolute',\n",
       "  'truth',\n",
       "  'verify',\n",
       "  'hundred',\n",
       "  'source',\n",
       "  'anti',\n",
       "  'semitism',\n",
       "  'scripted',\n",
       "  'propaganda',\n",
       "  'truth',\n",
       "  'muslim',\n",
       "  'walking',\n",
       "  'away',\n",
       "  'islam',\n",
       "  'people',\n",
       "  'converting',\n",
       "  'education',\n",
       "  'kill',\n",
       "  'say',\n",
       "  'must',\n",
       "  'murdering',\n",
       "  'fascist',\n",
       "  'follow',\n",
       "  'book',\n",
       "  'right',\n",
       "  'living',\n",
       "  'severe',\n",
       "  'delusion',\n",
       "  'reason',\n",
       "  'mohammed',\n",
       "  'hated',\n",
       "  'jew',\n",
       "  'willing',\n",
       "  'convert',\n",
       "  'million',\n",
       "  'african',\n",
       "  'murdered',\n",
       "  'islam',\n",
       "  've',\n",
       "  'seen',\n",
       "  'microbrain',\n",
       "  'told',\n",
       "  'every',\n",
       "  'verse',\n",
       "  'tao',\n",
       "  'te',\n",
       "  'ching',\n",
       "  'superior',\n",
       "  'every',\n",
       "  'verse',\n",
       "  'quran',\n",
       "  'brain',\n",
       "  'would',\n",
       "  'revolted',\n",
       "  'islam',\n",
       "  'isi',\n",
       "  'different',\n",
       "  'max',\n",
       "  'friend',\n",
       "  'hamas',\n",
       "  'isi',\n",
       "  'throw',\n",
       "  'gay',\n",
       "  'rooftop',\n",
       "  'hamas',\n",
       "  'beheads',\n",
       "  'gay',\n",
       "  'lesson',\n",
       "  'world',\n",
       "  'learned',\n",
       "  'islam',\n",
       "  'get',\n",
       "  'rid',\n",
       "  'brutal',\n",
       "  'dictator',\n",
       "  'replaced',\n",
       "  'brutal',\n",
       "  'islamist',\n",
       "  'that',\n",
       "  'complete',\n",
       "  'lie',\n",
       "  'murdered',\n",
       "  'unarmed',\n",
       "  'ezidi',\n",
       "  'civilian',\n",
       "  'done',\n",
       "  'nothing',\n",
       "  'enslaved',\n",
       "  'woman',\n",
       "  'islam',\n",
       "  'nothing',\n",
       "  'freeze',\n",
       "  'status',\n",
       "  'woman',\n",
       "  'century',\n",
       "  'denouncing',\n",
       "  'terrorism',\n",
       "  'violence',\n",
       "  'mean',\n",
       "  'denouncing',\n",
       "  'heart',\n",
       "  'islam',\n",
       "  'amazing',\n",
       "  'often',\n",
       "  'allah',\n",
       "  'revelation',\n",
       "  'met',\n",
       "  'mohammed',\n",
       "  'desire',\n",
       "  'one',\n",
       "  'became',\n",
       "  'suspicious',\n",
       "  'except',\n",
       "  'aisha',\n",
       "  'muslim',\n",
       "  'exterminated',\n",
       "  'christian',\n",
       "  'jew',\n",
       "  'continue',\n",
       "  'today',\n",
       "  'un',\n",
       "  'resolution',\n",
       "  'old',\n",
       "  'lie',\n",
       "  'property',\n",
       "  'right',\n",
       "  'arab',\n",
       "  'woman',\n",
       "  'islam',\n",
       "  'furthermore',\n",
       "  'many',\n",
       "  'muslim',\n",
       "  'country',\n",
       "  'even',\n",
       "  'record',\n",
       "  'system',\n",
       "  'account',\n",
       "  'murder',\n",
       "  'proving',\n",
       "  'muslim',\n",
       "  'liar',\n",
       "  'muslim',\n",
       "  'student',\n",
       "  'usc',\n",
       "  'hadith',\n",
       "  'database',\n",
       "  'muslim',\n",
       "  'virtually',\n",
       "  'killing',\n",
       "  'example',\n",
       "  'civilian',\n",
       "  'killed',\n",
       "  'afghanistan',\n",
       "  'killed',\n",
       "  'taliban',\n",
       "  'follower',\n",
       "  'religion',\n",
       "  'give',\n",
       "  'shit',\n",
       "  'prophet',\n",
       "  'religion',\n",
       "  'example',\n",
       "  'always',\n",
       "  'rt',\n",
       "  'spent',\n",
       "  'morning',\n",
       "  'board',\n",
       "  'election',\n",
       "  'getting',\n",
       "  'map',\n",
       "  'data',\n",
       "  'start',\n",
       "  'registering',\n",
       "  'every',\n",
       "  'black',\n",
       "  'person',\n",
       "  'ht',\n",
       "  'could',\n",
       "  'care',\n",
       "  'le',\n",
       "  'much',\n",
       "  'love',\n",
       "  'fraud',\n",
       "  'right',\n",
       "  'think',\n",
       "  'way',\n",
       "  'want',\n",
       "  'express',\n",
       "  'discovery',\n",
       "  'made',\n",
       "  'despite',\n",
       "  'islam',\n",
       "  'islam',\n",
       "  'contributed',\n",
       "  'nothing',\n",
       "  'mankind',\n",
       "  'year',\n",
       "  'muslim',\n",
       "  'kill',\n",
       "  'time',\n",
       "  'many',\n",
       "  'innocent',\n",
       "  'non',\n",
       "  'muslim',\n",
       "  'every',\n",
       "  'day',\n",
       "  'care',\n",
       "  'earthly',\n",
       "  'tyrant',\n",
       "  'also',\n",
       "  'egotistical',\n",
       "  'want',\n",
       "  'everyone',\n",
       "  'admire',\n",
       "  'bow',\n",
       "  'quran',\n",
       "  'writer',\n",
       "  'imagined',\n",
       "  'god',\n",
       "  'course',\n",
       "  'campaigning',\n",
       "  'destruction',\n",
       "  'israeli',\n",
       "  'racist',\n",
       "  'anti',\n",
       "  'semite',\n",
       "  'asshole',\n",
       "  'rt',\n",
       "  'islam',\n",
       "  'war',\n",
       "  'woman',\n",
       "  'continues',\n",
       "  'islam',\n",
       "  'continues',\n",
       "  'show',\n",
       "  'value',\n",
       "  'woman',\n",
       "  'factual',\n",
       "  'evidence',\n",
       "  'never',\n",
       "  'million',\n",
       "  'native',\n",
       "  'american',\n",
       "  'indian',\n",
       "  'north',\n",
       "  'american',\n",
       "  'continent',\n",
       "  'rt',\n",
       "  'uk',\n",
       "  'like',\n",
       "  'idiot',\n",
       "  'give',\n",
       "  'jihadis',\n",
       "  'rehabilitation',\n",
       "  'jordan',\n",
       "  'execute',\n",
       "  'joke',\n",
       "  'support',\n",
       "  'tyrant',\n",
       "  'islam',\n",
       "  'produce',\n",
       "  'nothing',\n",
       "  'tyrant',\n",
       "  'caliph',\n",
       "  'sultan',\n",
       "  'tyrant',\n",
       "  'muslim',\n",
       "  'robbed',\n",
       "  'wealthy',\n",
       "  'merchant',\n",
       "  'saudi',\n",
       "  'cleric',\n",
       "  'sun',\n",
       "  'revolves',\n",
       "  'around',\n",
       "  'earth',\n",
       "  'understand',\n",
       "  'madrassa',\n",
       "  'graduate',\n",
       "  'skill',\n",
       "  'jihad',\n",
       "  'islam',\n",
       "  'created',\n",
       "  'monster',\n",
       "  'islam',\n",
       "  'creating',\n",
       "  'year',\n",
       "  'allah',\n",
       "  'word',\n",
       "  'filth',\n",
       "  'hatred',\n",
       "  'phony',\n",
       "  'seen',\n",
       "  'jew',\n",
       "  'go',\n",
       "  'killing',\n",
       "  'rampage',\n",
       "  'holocaust',\n",
       "  'denier',\n",
       "  'violence',\n",
       "  'islam',\n",
       "  'answer',\n",
       "  'everything',\n",
       "  'say',\n",
       "  'drink',\n",
       "  'wine',\n",
       "  'heaven',\n",
       "  'islamic',\n",
       "  'heaven',\n",
       "  'basically',\n",
       "  'drunken',\n",
       "  'whore',\n",
       "  'house',\n",
       "  'spiritual',\n",
       "  'lol',\n",
       "  'claim',\n",
       "  'oh',\n",
       "  'insulted',\n",
       "  'religion',\n",
       "  'kill',\n",
       "  'child',\n",
       "  'grow',\n",
       "  'fairy',\n",
       "  'tale',\n",
       "  'muslim',\n",
       "  'never',\n",
       "  'grow',\n",
       "  'santa',\n",
       "  'white',\n",
       "  'entire',\n",
       "  'nation',\n",
       "  'saudi',\n",
       "  'punnished',\n",
       "  'since',\n",
       "  'allow',\n",
       "  'church',\n",
       "  'bible',\n",
       "  'tell',\n",
       "  'something',\n",
       "  'isi',\n",
       "  'mohammed',\n",
       "  'freedom',\n",
       "  'impose',\n",
       "  'religion',\n",
       "  'others',\n",
       "  'islam',\n",
       "  'yes',\n",
       "  'might',\n",
       "  'power',\n",
       "  'imperialism',\n",
       "  'zero',\n",
       "  'spirituality',\n",
       "  'soon',\n",
       "  'world',\n",
       "  'understand',\n",
       "  'see',\n",
       "  'burning',\n",
       "  'civilian',\n",
       "  'picture',\n",
       "  'even',\n",
       "  'burning',\n",
       "  'house',\n",
       "  'million',\n",
       "  'muslim',\n",
       "  'extremist',\n",
       "  'matter',\n",
       "  'desperately',\n",
       "  'race',\n",
       "  'baiting',\n",
       "  'trash',\n",
       "  'like',\n",
       "  'want',\n",
       "  'islam',\n",
       "  'race',\n",
       "  'like',\n",
       "  'said',\n",
       "  'stupid',\n",
       "  'comment',\n",
       "  'seek',\n",
       "  'hide',\n",
       "  'vileness',\n",
       "  'islam',\n",
       "  'rt',\n",
       "  'muslim',\n",
       "  'protest',\n",
       "  'complete',\n",
       "  'failure',\n",
       "  'aussie',\n",
       "  'want',\n",
       "  'islam',\n",
       "  'suit',\n",
       "  'way',\n",
       "  'life',\n",
       "  'every',\n",
       "  'jew',\n",
       "  'like',\n",
       "  'thousand',\n",
       "  'muslim',\n",
       "  'like',\n",
       "  'problem',\n",
       "  'far',\n",
       "  'knowledge',\n",
       "  'islam',\n",
       "  'mind',\n",
       "  'shrunken',\n",
       "  'islam',\n",
       "  'execution',\n",
       "  'that',\n",
       "  'one',\n",
       "  'tenth',\n",
       "  'day',\n",
       "  'worth',\n",
       "  'islamically',\n",
       "  'correct',\n",
       "  'isi',\n",
       "  'justifying',\n",
       "  'christianity',\n",
       "  'microbrain',\n",
       "  'religion',\n",
       "  'hiding',\n",
       "  'islamic',\n",
       "  'barbarity',\n",
       "  'billion',\n",
       "  'muslim',\n",
       "  'idiot',\n",
       "  'size',\n",
       "  'population',\n",
       "  'contribute',\n",
       "  'virtually',\n",
       "  'nothing',\n",
       "  'every',\n",
       "  'muslim',\n",
       "  'state',\n",
       "  'nasty',\n",
       "  'place',\n",
       "  'muslim',\n",
       "  'blumenthal',\n",
       "  'ever',\n",
       "  'written',\n",
       "  'ceaseless',\n",
       "  'muslim',\n",
       "  'violence',\n",
       "  'hindu',\n",
       "  'bangladesh',\n",
       "  'practicing',\n",
       "  'islam',\n",
       "  'vomiting',\n",
       "  'jew',\n",
       "  'christian',\n",
       "  'non',\n",
       "  'believer',\n",
       "  'check',\n",
       "  'code',\n",
       "  'umar',\n",
       "  'three',\n",
       "  'translation',\n",
       "  'quran',\n",
       "  'microbrain',\n",
       "  'know',\n",
       "  'far',\n",
       "  'islam',\n",
       "  'idiot',\n",
       "  'like',\n",
       "  'making',\n",
       "  'declaration',\n",
       "  'contact',\n",
       "  'reality',\n",
       "  'islam',\n",
       "  'inhuman',\n",
       "  'must',\n",
       "  'outlawed',\n",
       "  'rt',\n",
       "  'prophet',\n",
       "  'honor',\n",
       "  'rape',\n",
       "  'beheading',\n",
       "  'genocide',\n",
       "  'honor',\n",
       "  'muhammad',\n",
       "  'deserve',\n",
       "  'respect',\n",
       "  'quran',\n",
       "  'would',\n",
       "  'good',\n",
       "  'example',\n",
       "  'terrorism',\n",
       "  'phobia',\n",
       "  'irrational',\n",
       "  'hatred',\n",
       "  'thing',\n",
       "  'phobia',\n",
       "  'hatred',\n",
       "  'rational',\n",
       "  'islam',\n",
       "  'religion',\n",
       "  'zero',\n",
       "  'spiritual',\n",
       "  'content',\n",
       "  'tell',\n",
       "  'exactly',\n",
       "  'wipe',\n",
       "  'as',\n",
       "  'furthermore',\n",
       "  'islam',\n",
       "  'demand',\n",
       "  'woman',\n",
       "  'locked',\n",
       "  'home',\n",
       "  'covered',\n",
       "  'stop',\n",
       "  'lying',\n",
       "  ...]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing the dataset\n",
    "\n",
    "tweets = \" \".join(tw for tw in twitter_df.tokenized)\n",
    "all_sentences = nltk.sent_tokenize(tweets)\n",
    "\n",
    "all_words = [nltk.word_tokenize(sent) for sent in all_sentences]\n",
    "\n",
    "all_words[:10]\n",
    "#stemmed_tokens = pd.Series(df['stemmed_tokens']).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [wrong, isi, follows, example, mohammed, quran...\n",
      "1         [good, muslim, good, despite, bad, religion]\n",
      "2    [yeah, called, caring, human, life, idiot, som...\n",
      "3    [muslim, brain, dead, repeat, others, said, mi...\n",
      "4    [want, understand, lie, muslim, living, peace,...\n",
      "5    [total, liar, like, pedophile, prophet, un, so...\n",
      "6    [daesh, shia, militia, driven, religion, hatre...\n",
      "7    [muslim, world, ever, produced, anything, tyra...\n",
      "8    [islam, answer, anything, pretend, answer, ill...\n",
      "9    [attacking, everyone, follows, religious, cult...\n",
      "Name: tokenized_text, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [wrong, isi, follow, exampl, moham, quran, exa...\n",
       "1          [good, muslim, good, despit, bad, religion]\n",
       "2    [yeah, call, care, human, life, idiot, someth,...\n",
       "3    [muslim, brain, dead, repeat, other, said, mil...\n",
       "4    [want, understand, lie, muslim, live, peac, je...\n",
       "5    [total, liar, like, pedophil, prophet, un, sol...\n",
       "6    [daesh, shia, militia, driven, religion, hatr,...\n",
       "7    [muslim, world, ever, produc, anyth, tyrant, d...\n",
       "8    [islam, answer, anyth, pretend, answer, illog,...\n",
       "9    [attack, everyon, follow, religi, cult, hate, ...\n",
       "Name: stemmed_tokens, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize the text column to get the new column 'tokenized_text'\n",
    "twitter_df['tokenized_text'] = [simple_preprocess(line, deacc=True) for line in twitter_df['tokenized']] \n",
    "print(twitter_df['tokenized_text'].head(10))\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "# Get the stemmed_tokens\n",
    "twitter_df['stemmed_tokens'] = [[porter_stemmer.stem(word) for word in tokens] for tokens in twitter_df['tokenized_text'] ]\n",
    "twitter_df['stemmed_tokens'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(twitter_df[['stemmed_tokens']], twitter_df['oh_label'], stratify=twitter_df['oh_label'], random_state=42)\n",
    "X_train = X_train.reset_index()\n",
    "X_test = X_test.reset_index()\n",
    "y_train = y_train.to_frame()\n",
    "y_train = y_train.reset_index()\n",
    "y_test = y_test.to_frame()\n",
    "y_test = y_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for later\n",
    "X_train.to_csv(\"data/X_train.csv\")\n",
    "X_test.to_csv(\"data/X_test.csv\")\n",
    "y_train.to_csv(\"data/y_train.csv\")\n",
    "y_test.to_csv(\"data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list(['hi', 'wifion', 'thank', 'much', 'patient', 'address', 'comment', 'sorri', 'get', 'back', 'earlier', 'understand', 'relev', 'guidelin', 'seem', 'wp', 'undu', 'content', 'mai', 'satisfi', 'requir', 'major', 'view', 'also', 'understand', 'point', 'involv', 'parti', 'court', 'case', 'becom', 'primari', 'sourc', 'topic', 'relat', 'case', 'per', 'notw', 'exampl', 'still', 'convinc', 'bar', 'bench', 'reliabl', 'sourc', 'll', 'try', 'look', 'bit', 'see', 'rational', 'us', 'particularli', 'case', 'blp', 'somewhat', 'specul', 'question', 'suppos', 'court', 'case', 'settl', 'suffici', 'medium', 'coverag', 'would', 'lawsuit', 'notabl', 'enough', 'articl', 'would', 'subject', 'blp', 'restrict', 'anywai', 'thank', 'help']),\n",
       "       list(['serious', 'believ', 'episod', 'air', 'cancel', 'show', 'pleas', 'explain', 'known', 'provid', 'refer', 'verifi']),\n",
       "       list(['good', 'point', 'expect', 'see', 'articl', 'delet', 'bother', 'clear', 'wikipedia', 'truli', 'repres', 'forum', 'taken', 'hack', 'zealot', 'vandal', 'becom', 'adminsitr', 'larg', 'would', 'appear', 'base', 'connolli', 'bio', 'due', 'fact', 'product', 'employ', 'oblig', 'elsewher', 'fortun', 'oblig', 'expect', 'yell', 'scream', 'revert', 'control', 'ultim', 'howev', 'alter', 'fact', 'wrong', 'fundament', 'philosophi', 'new', 'fascism', 'ultim', 'die', 'form', 'issu', 'realli', 'mani', 'peopl', 'harm', 'fascist', 'us', 'global', 'weapon', 'latest', 'justif', 'increas', 'state', 'control', 'life', 'follow', 'racial', 'argument', 'nationalist', 'argument', 'worker', 'right', 'argument', 'lol', 've', 'busi', 'thing', 've', 'even', 'forgotten', 'insert', 'signatur']),\n",
       "       ..., list(['oh', 'lower', 'case', 'alreadi', 'fix']),\n",
       "       list(['ag', 'stretch', 'articl', 'run', 'room', 'ned', 'page', 'stretch']),\n",
       "       list(['sinc', 'particip', 'discuss', 'pizzl', 'hy', 'would', 'feign', 'ignor'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word2vec_model_file = \"model/twitter_all_data.csv\" + 'word2vec_' + '.model'\n",
    "word2vec_model_file = \"model/twitter_train_data.csv\" + 'word2vec_' + '.model'\n",
    "\n",
    "stemmed_tokens = pd.Series(X_train['stemmed_tokens']).values\n",
    "stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to train word2vec model: 34.105093240737915\n"
     ]
    }
   ],
   "source": [
    "# Train the Word2Vec Model (Skip-gram model (sg = 1))\n",
    "start_time = time.time()\n",
    "\n",
    "w2v_model = Word2Vec(stemmed_tokens, vector_size=100,min_count = 1, workers = 4, window = 3, sg = 1)\n",
    "print(\"Time taken to train word2vec model: \" + str(time.time() - start_time))\n",
    "w2v_model.save(word2vec_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(w2v_model.wv.key_to_index))\n",
    "w2v_model.wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126579"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stepped_list = list(itertools.chain.from_iterable(stemmed_tokens.tolist()))\n",
    "len(set(stepped_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('religi', 0.8370547294616699), ('humanist', 0.8314415216445923), ('islam', 0.8253030776977539), ('creed', 0.8213331699371338), ('hinduism', 0.819883406162262), ('atheism', 0.8170770406723022), ('judaism', 0.8143739104270935), ('irreligion', 0.8069251775741577), ('monotheist', 0.8062925338745117), ('sikhism', 0.8054744601249695)]\n",
      "[('feminist', 0.8098196983337402), ('egalitarian', 0.7891940474510193), ('paglia', 0.7797747850418091), ('nambla', 0.7643048167228699), ('overtli', 0.7521183490753174), ('conservat', 0.7409563064575195), ('movement', 0.7394248247146606), ('persuas', 0.7275168299674988), ('paranorm', 0.7261168360710144), ('subcultur', 0.723408043384552)]\n",
      "[('other', 0.7898426651954651), ('fervent', 0.7837676405906677), ('instinct', 0.783477783203125), ('terroris', 0.7691183090209961), ('profoundli', 0.7682755589485168), ('fierc', 0.7667680978775024), ('pitchfork', 0.763868510723114), ('shun', 0.7602774500846863), ('deepak', 0.7602328658103943), ('appeas', 0.7536629438400269)]\n"
     ]
    }
   ],
   "source": [
    "print(w2v_model.wv.most_similar('religion'))\n",
    "print(w2v_model.wv.most_similar('femin'))\n",
    "print(w2v_model.wv.most_similar('peopl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>annotation</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>cat_enc</th>\n",
       "      <th>ed_label_0</th>\n",
       "      <th>ed_label_1</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>@g0ssipsquirrelx Wrong, ISIS follows the examp...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>wrong isi follows example mohammed quran exactly</td>\n",
       "      <td>[wrong, isi, follows, example, mohammed, quran...</td>\n",
       "      <td>[wrong, isi, follow, exampl, moham, quran, exa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>@SirajZarook @OdiniaInvictus @BilalIGhumman @I...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>good muslim good despite bad religion</td>\n",
       "      <td>[good, muslim, good, despite, bad, religion]</td>\n",
       "      <td>[good, muslim, good, despit, bad, religion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>@scamp_faridxx @AbuAlbaraaSham Yeah, it's call...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>yeah called caring human life idiot something ...</td>\n",
       "      <td>[yeah, called, caring, human, life, idiot, som...</td>\n",
       "      <td>[yeah, call, care, human, life, idiot, someth,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>@Asadumarfans You are a Muslim. You are brain ...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>muslim brain dead repeat others said million time</td>\n",
       "      <td>[muslim, brain, dead, repeat, others, said, mi...</td>\n",
       "      <td>[muslim, brain, dead, repeat, other, said, mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>@harmlesstree2 @MaxBlumenthal If you want to u...</td>\n",
       "      <td>racism</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>want understand lie muslim living peace jew re...</td>\n",
       "      <td>[want, understand, lie, muslim, living, peace,...</td>\n",
       "      <td>[want, understand, lie, muslim, live, peac, je...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0             0           0   \n",
       "1             1             1           1   \n",
       "2             2             2           2   \n",
       "3             3             3           3   \n",
       "4             4             4           4   \n",
       "\n",
       "                                                text annotation  oh_label  \\\n",
       "0  @g0ssipsquirrelx Wrong, ISIS follows the examp...     racism       1.0   \n",
       "1  @SirajZarook @OdiniaInvictus @BilalIGhumman @I...     racism       1.0   \n",
       "2  @scamp_faridxx @AbuAlbaraaSham Yeah, it's call...     racism       1.0   \n",
       "3  @Asadumarfans You are a Muslim. You are brain ...     racism       1.0   \n",
       "4  @harmlesstree2 @MaxBlumenthal If you want to u...     racism       1.0   \n",
       "\n",
       "   cat_enc ed_label_0 ed_label_1 hashtags  \\\n",
       "0        1                             []   \n",
       "1        1                             []   \n",
       "2        1                             []   \n",
       "3        1                             []   \n",
       "4        1                             []   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0   wrong isi follows example mohammed quran exactly   \n",
       "1              good muslim good despite bad religion   \n",
       "2  yeah called caring human life idiot something ...   \n",
       "3  muslim brain dead repeat others said million time   \n",
       "4  want understand lie muslim living peace jew re...   \n",
       "\n",
       "                                      tokenized_text  \\\n",
       "0  [wrong, isi, follows, example, mohammed, quran...   \n",
       "1       [good, muslim, good, despite, bad, religion]   \n",
       "2  [yeah, called, caring, human, life, idiot, som...   \n",
       "3  [muslim, brain, dead, repeat, others, said, mi...   \n",
       "4  [want, understand, lie, muslim, living, peace,...   \n",
       "\n",
       "                                      stemmed_tokens  \n",
       "0  [wrong, isi, follow, exampl, moham, quran, exa...  \n",
       "1        [good, muslim, good, despit, bad, religion]  \n",
       "2  [yeah, call, care, human, life, idiot, someth,...  \n",
       "3  [muslim, brain, dead, repeat, other, said, mil...  \n",
       "4  [want, understand, lie, muslim, live, peac, je...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.to_csv(\"data/twitter_all_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.2</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>annotation</th>\n",
       "      <th>oh_label</th>\n",
       "      <th>cat_enc</th>\n",
       "      <th>ed_label_0</th>\n",
       "      <th>ed_label_1</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>stemmed_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0.2, Unnamed: 0.1, Unnamed: 0, text, annotation, oh_label, cat_enc, ed_label_0, ed_label_1, hashtags, tokenized, tokenized_text, stemmed_tokens]\n",
       "Index: []"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df[twitter_df['oh_label'].isna()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
